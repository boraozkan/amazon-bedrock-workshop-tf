{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc40c48b-0c95-4757-a067-563cfccd51a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Invoke Bedrock model for text generation using zero-shot prompt\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a413e2-3c34-4073-9000-d8556537bb6a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we show you how to use a LLM to generate an email response to a customer who provided negative feedback on the quality of customer service that they received from the support engineer. \n",
    "\n",
    "We will use Meta's Llama 2 large model using the Boto3 API. \n",
    "\n",
    "The prompt used in this example is called a zero-shot prompt because we are not providing any examples of text alongside their classification other than the prompt.\n",
    "\n",
    "**Note:** *This notebook can be run within or outside of AWS environment.*\n",
    "\n",
    "#### Context\n",
    "To demonstrate the text generation capability of Amazon Bedrock, we will explore the use of Boto3 client to communicate with Amazon Bedrock API. We will demonstrate different configurations available as well as how simple input can lead to desired outputs.\n",
    "\n",
    "#### Pattern\n",
    "We will simply provide the Amazon Bedrock API with an input consisting of a task, an instruction and an input for the model under the hood to generate an output without providing any additional example. The purpose here is to demonstrate how the powerful LLMs easily understand the task at hand and generate compelling outputs.\n",
    "\n",
    "![](./images/bedrock.jpg)\n",
    "\n",
    "#### Use case\n",
    "To demonstrate the generation capability of models in Amazon Bedrock, let's take the use case of email generation.\n",
    "\n",
    "#### Persona\n",
    "You are Bob a Customer Service Manager at AnyCompany and some of your customers are not happy with the customer service and are providing negative feedbacks on the service provided by customer support engineers. Now, you would like to respond to those customers humbly aplogizing for the poor service and regain trust. You need the help of an LLM to generate a bulk of emails for you which are human friendly and personalized to the customer's sentiment from previous email correspondence.\n",
    "\n",
    "#### Implementation\n",
    "To fulfill this use case, in this notebook we will show how to generate an email with a thank you note based on the customer's previous email.We will use the Meta Llama 2 Text Large model using the Amazon Bedrock API with Boto3 client. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64baae27-2660-4a1e-b2e5-3de49d069362",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "⚠️ ⚠️ ⚠️ Before running this notebook, ensure you've run the [Bedrock boto3 setup notebook](../00_Intro/bedrock_boto3_setup.ipynb#Prerequisites) notebook. ⚠️ ⚠️ ⚠️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776fd083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f634211-3de1-4390-8c3f-367af5554c39",
   "metadata": {},
   "source": [
    "## Generate text\n",
    "\n",
    "Following on the use case explained above, let's prepare an input for  the Amazon Bedrock service to generate an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ee2bae-6415-4dba-af98-a19028305c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the prompt\n",
    "prompt_data = \"\"\"\n",
    "Command: Write an email from Bob, Customer Service Manager, to the customer \"John Doe\" \n",
    "who provided negative feedback on the service provided by our customer support \n",
    "engineer\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9784e5-5e9d-472d-8ef1-34108ee4968b",
   "metadata": {},
   "source": [
    "Let's start by using the Meta's Llama 2 Large model. Meta Llama 2 Large supports a context window of ~4k tokens and accepts the following parameters:\n",
    "- `inputText`: Prompt to the LLM\n",
    "- `textGenerationConfig`: These are the parameters that model will take into account while generating the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af670eb-ad02-40df-a19c-3ed835fac8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = json.dumps({ \n",
    "\t'prompt': prompt_data,\n",
    "    'max_gen_len': 512,\n",
    "\t'top_p': 0.9,\n",
    "\t'temperature': 0.2\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca6751",
   "metadata": {},
   "source": [
    "The Amazon Bedrock API provides you with an API `invoke_model` which accepts the following:\n",
    "- `modelId`: This is the model ARN for the various foundation models available under Amazon Bedrock\n",
    "- `accept`: The type of input request\n",
    "- `contentType`: The content type of the output\n",
    "- `body`: A json string consisting of the prompt and the configurations\n",
    "\n",
    "Check [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html) for Available text generation model Ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088cf6bf-dd73-4710-a0cc-6c11d220c431",
   "metadata": {},
   "source": [
    "#### Invoke the Meta's Llama 2 Large language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379498f2",
   "metadata": {},
   "source": [
    "First, we explore how the model generates an output based on the prompt created earlier.\n",
    "\n",
    "##### Complete Output Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecaceef1-0f7f-4ae5-8007-ff7c25335251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelId = 'meta.llama2-13b-chat-v1' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "outputText = \"\\n\"\n",
    "try:\n",
    "\n",
    "    response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "\n",
    "    outputText = response_body['generation'].strip()\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3748383a-c140-407f-a7f6-8f140ad57680",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject: Apology and Resolution for Poor Service Experience\n",
      "\n",
      "Dear John,\n",
      "\n",
      "I am writing to express my sincerest apologies for the poor service experience you\n",
      "received from our customer support engineer, Jane Smith. We take all feedback\n",
      "seriously and are committed to providing the highest level of service to our\n",
      "customers.\n",
      "\n",
      "I have reviewed the details of your case and I want to assure you that we are taking\n",
      "appropriate actions to address the issues you encountered. Our customer support\n",
      "engineers are trained to provide professional and timely assistance, and it is\n",
      "disappointing to learn that Jane did not meet these expectations.\n",
      "\n",
      "To make up for the inconvenience and frustration caused, I would like to offer you\n",
      "a complimentary one-month subscription to our premium support service. This\n",
      "service includes priority support, dedicated account management, and access to\n",
      "our advanced technical resources. We hope that this gesture will demonstrate our\n",
      "commitment to your satisfaction and loyalty as a customer.\n",
      "\n",
      "Please let me know if there is anything else we can do to resolve this issue and\n",
      "improve your experience with our company. Your feedback is invaluable to us and\n",
      "will help us to improve our services.\n",
      "\n",
      "Thank you for bringing this to our attention, and we look forward to the\n",
      "opportunity to provide you with the high level of service that you expect from us.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Bob\n",
      "\n",
      "Customer Service Manager\n",
      "\n",
      "Company Name\n",
      "\n",
      "Email: [bob@companyname.com](mailto:bob@companyname.com)\n",
      "\n",
      "Phone: 555-555-5555\n",
      "\n",
      "Please note that the above email is just an example, and you should adjust the content and the tone\n",
      "according to your specific needs and the situation.\n"
     ]
    }
   ],
   "source": [
    "# The relevant portion of the response begins after the first newline character\n",
    "# Below we print the response beginning after the first occurence of '\\n'.\n",
    "\n",
    "email = outputText[outputText.index('\\n')+1:]\n",
    "print_ww(email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69e1a0",
   "metadata": {},
   "source": [
    "##### Streaming Output Generation\n",
    "Above is an example email generated by the Meta Llama 2 Large model by understanding the input request and using its inherent understanding of the different modalities. This request to the API is synchronous and waits for the entire output to be generated by the model.\n",
    "\n",
    "Bedrock also supports that the output can be streamed as it is generated by the model in form of chunks. Below is an example of invoking the model with streaming option. `invoke_model_with_response_stream` returns a `ResponseStream` which you can read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad073290",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\u001b[31m**Chunk 1**\u001b[0m\n",
      ",\n",
      "\n",
      "\t\t\u001b[31m**Chunk 2**\u001b[0m\n",
      " James\n",
      "\n",
      "\t\t\u001b[31m**Chunk 3**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 4**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 5**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 6**\u001b[0m\n",
      "Subject\n",
      "\n",
      "\t\t\u001b[31m**Chunk 7**\u001b[0m\n",
      ":\n",
      "\n",
      "\t\t\u001b[31m**Chunk 8**\u001b[0m\n",
      " Ap\n",
      "\n",
      "\t\t\u001b[31m**Chunk 9**\u001b[0m\n",
      "ology\n",
      "\n",
      "\t\t\u001b[31m**Chunk 10**\u001b[0m\n",
      " and\n",
      "\n",
      "\t\t\u001b[31m**Chunk 11**\u001b[0m\n",
      " Resol\n",
      "\n",
      "\t\t\u001b[31m**Chunk 12**\u001b[0m\n",
      "ution\n",
      "\n",
      "\t\t\u001b[31m**Chunk 13**\u001b[0m\n",
      " for\n",
      "\n",
      "\t\t\u001b[31m**Chunk 14**\u001b[0m\n",
      " Po\n",
      "\n",
      "\t\t\u001b[31m**Chunk 15**\u001b[0m\n",
      "or\n",
      "\n",
      "\t\t\u001b[31m**Chunk 16**\u001b[0m\n",
      " Service\n",
      "\n",
      "\t\t\u001b[31m**Chunk 17**\u001b[0m\n",
      " Exper\n",
      "\n",
      "\t\t\u001b[31m**Chunk 18**\u001b[0m\n",
      "ience\n",
      "\n",
      "\t\t\u001b[31m**Chunk 19**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 20**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 21**\u001b[0m\n",
      "D\n",
      "\n",
      "\t\t\u001b[31m**Chunk 22**\u001b[0m\n",
      "ear\n",
      "\n",
      "\t\t\u001b[31m**Chunk 23**\u001b[0m\n",
      " John\n",
      "\n",
      "\t\t\u001b[31m**Chunk 24**\u001b[0m\n",
      ",\n",
      "\n",
      "\t\t\u001b[31m**Chunk 25**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 26**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 27**\u001b[0m\n",
      "I\n",
      "\n",
      "\t\t\u001b[31m**Chunk 28**\u001b[0m\n",
      " am\n",
      "\n",
      "\t\t\u001b[31m**Chunk 29**\u001b[0m\n",
      " writing\n",
      "\n",
      "\t\t\u001b[31m**Chunk 30**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 31**\u001b[0m\n",
      " apolog\n",
      "\n",
      "\t\t\u001b[31m**Chunk 32**\u001b[0m\n",
      "ize\n",
      "\n",
      "\t\t\u001b[31m**Chunk 33**\u001b[0m\n",
      " for\n",
      "\n",
      "\t\t\u001b[31m**Chunk 34**\u001b[0m\n",
      " the\n",
      "\n",
      "\t\t\u001b[31m**Chunk 35**\u001b[0m\n",
      " poor\n",
      "\n",
      "\t\t\u001b[31m**Chunk 36**\u001b[0m\n",
      " service\n",
      "\n",
      "\t\t\u001b[31m**Chunk 37**\u001b[0m\n",
      " experience\n",
      "\n",
      "\t\t\u001b[31m**Chunk 38**\u001b[0m\n",
      " you\n",
      "\n",
      "\t\t\u001b[31m**Chunk 39**\u001b[0m\n",
      " recently\n",
      "\n",
      "\t\t\u001b[31m**Chunk 40**\u001b[0m\n",
      " had\n",
      "\n",
      "\t\t\u001b[31m**Chunk 41**\u001b[0m\n",
      " with\n",
      "\n",
      "\t\t\u001b[31m**Chunk 42**\u001b[0m\n",
      " our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 43**\u001b[0m\n",
      " customer\n",
      "\n",
      "\t\t\u001b[31m**Chunk 44**\u001b[0m\n",
      " support\n",
      "\n",
      "\t\t\u001b[31m**Chunk 45**\u001b[0m\n",
      " engineer\n",
      "\n",
      "\t\t\u001b[31m**Chunk 46**\u001b[0m\n",
      ",\n",
      "\n",
      "\t\t\u001b[31m**Chunk 47**\u001b[0m\n",
      " James\n",
      "\n",
      "\t\t\u001b[31m**Chunk 48**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 49**\u001b[0m\n",
      " We\n",
      "\n",
      "\t\t\u001b[31m**Chunk 50**\u001b[0m\n",
      " take\n",
      "\n",
      "\t\t\u001b[31m**Chunk 51**\u001b[0m\n",
      " all\n",
      "\n",
      "\t\t\u001b[31m**Chunk 52**\u001b[0m\n",
      " feedback\n",
      "\n",
      "\t\t\u001b[31m**Chunk 53**\u001b[0m\n",
      " seriously\n",
      "\n",
      "\t\t\u001b[31m**Chunk 54**\u001b[0m\n",
      " and\n",
      "\n",
      "\t\t\u001b[31m**Chunk 55**\u001b[0m\n",
      " are\n",
      "\n",
      "\t\t\u001b[31m**Chunk 56**\u001b[0m\n",
      " committed\n",
      "\n",
      "\t\t\u001b[31m**Chunk 57**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 58**\u001b[0m\n",
      " providing\n",
      "\n",
      "\t\t\u001b[31m**Chunk 59**\u001b[0m\n",
      " the\n",
      "\n",
      "\t\t\u001b[31m**Chunk 60**\u001b[0m\n",
      " highest\n",
      "\n",
      "\t\t\u001b[31m**Chunk 61**\u001b[0m\n",
      " level\n",
      "\n",
      "\t\t\u001b[31m**Chunk 62**\u001b[0m\n",
      " of\n",
      "\n",
      "\t\t\u001b[31m**Chunk 63**\u001b[0m\n",
      " service\n",
      "\n",
      "\t\t\u001b[31m**Chunk 64**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 65**\u001b[0m\n",
      " our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 66**\u001b[0m\n",
      " customers\n",
      "\n",
      "\t\t\u001b[31m**Chunk 67**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 68**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 69**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 70**\u001b[0m\n",
      "I\n",
      "\n",
      "\t\t\u001b[31m**Chunk 71**\u001b[0m\n",
      " have\n",
      "\n",
      "\t\t\u001b[31m**Chunk 72**\u001b[0m\n",
      " review\n",
      "\n",
      "\t\t\u001b[31m**Chunk 73**\u001b[0m\n",
      "ed\n",
      "\n",
      "\t\t\u001b[31m**Chunk 74**\u001b[0m\n",
      " the\n",
      "\n",
      "\t\t\u001b[31m**Chunk 75**\u001b[0m\n",
      " details\n",
      "\n",
      "\t\t\u001b[31m**Chunk 76**\u001b[0m\n",
      " of\n",
      "\n",
      "\t\t\u001b[31m**Chunk 77**\u001b[0m\n",
      " your\n",
      "\n",
      "\t\t\u001b[31m**Chunk 78**\u001b[0m\n",
      " case\n",
      "\n",
      "\t\t\u001b[31m**Chunk 79**\u001b[0m\n",
      " and\n",
      "\n",
      "\t\t\u001b[31m**Chunk 80**\u001b[0m\n",
      " I\n",
      "\n",
      "\t\t\u001b[31m**Chunk 81**\u001b[0m\n",
      " want\n",
      "\n",
      "\t\t\u001b[31m**Chunk 82**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 83**\u001b[0m\n",
      " ass\n",
      "\n",
      "\t\t\u001b[31m**Chunk 84**\u001b[0m\n",
      "ure\n",
      "\n",
      "\t\t\u001b[31m**Chunk 85**\u001b[0m\n",
      " you\n",
      "\n",
      "\t\t\u001b[31m**Chunk 86**\u001b[0m\n",
      " that\n",
      "\n",
      "\t\t\u001b[31m**Chunk 87**\u001b[0m\n",
      " we\n",
      "\n",
      "\t\t\u001b[31m**Chunk 88**\u001b[0m\n",
      " are\n",
      "\n",
      "\t\t\u001b[31m**Chunk 89**\u001b[0m\n",
      " taking\n",
      "\n",
      "\t\t\u001b[31m**Chunk 90**\u001b[0m\n",
      " immediate\n",
      "\n",
      "\t\t\u001b[31m**Chunk 91**\u001b[0m\n",
      " action\n",
      "\n",
      "\t\t\u001b[31m**Chunk 92**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 93**\u001b[0m\n",
      " address\n",
      "\n",
      "\t\t\u001b[31m**Chunk 94**\u001b[0m\n",
      " the\n",
      "\n",
      "\t\t\u001b[31m**Chunk 95**\u001b[0m\n",
      " issues\n",
      "\n",
      "\t\t\u001b[31m**Chunk 96**\u001b[0m\n",
      " you\n",
      "\n",
      "\t\t\u001b[31m**Chunk 97**\u001b[0m\n",
      " encountered\n",
      "\n",
      "\t\t\u001b[31m**Chunk 98**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 99**\u001b[0m\n",
      " Our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 100**\u001b[0m\n",
      " team\n",
      "\n",
      "\t\t\u001b[31m**Chunk 101**\u001b[0m\n",
      " is\n",
      "\n",
      "\t\t\u001b[31m**Chunk 102**\u001b[0m\n",
      " working\n",
      "\n",
      "\t\t\u001b[31m**Chunk 103**\u001b[0m\n",
      " dil\n",
      "\n",
      "\t\t\u001b[31m**Chunk 104**\u001b[0m\n",
      "ig\n",
      "\n",
      "\t\t\u001b[31m**Chunk 105**\u001b[0m\n",
      "ently\n",
      "\n",
      "\t\t\u001b[31m**Chunk 106**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 107**\u001b[0m\n",
      " resolve\n",
      "\n",
      "\t\t\u001b[31m**Chunk 108**\u001b[0m\n",
      " the\n",
      "\n",
      "\t\t\u001b[31m**Chunk 109**\u001b[0m\n",
      " problems\n",
      "\n",
      "\t\t\u001b[31m**Chunk 110**\u001b[0m\n",
      " you\n",
      "\n",
      "\t\t\u001b[31m**Chunk 111**\u001b[0m\n",
      " faced\n",
      "\n",
      "\t\t\u001b[31m**Chunk 112**\u001b[0m\n",
      " and\n",
      "\n",
      "\t\t\u001b[31m**Chunk 113**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 114**\u001b[0m\n",
      " prevent\n",
      "\n",
      "\t\t\u001b[31m**Chunk 115**\u001b[0m\n",
      " them\n",
      "\n",
      "\t\t\u001b[31m**Chunk 116**\u001b[0m\n",
      " from\n",
      "\n",
      "\t\t\u001b[31m**Chunk 117**\u001b[0m\n",
      " happening\n",
      "\n",
      "\t\t\u001b[31m**Chunk 118**\u001b[0m\n",
      " again\n",
      "\n",
      "\t\t\u001b[31m**Chunk 119**\u001b[0m\n",
      " in\n",
      "\n",
      "\t\t\u001b[31m**Chunk 120**\u001b[0m\n",
      " the\n",
      "\n",
      "\t\t\u001b[31m**Chunk 121**\u001b[0m\n",
      " future\n",
      "\n",
      "\t\t\u001b[31m**Chunk 122**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 123**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 124**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 125**\u001b[0m\n",
      "As\n",
      "\n",
      "\t\t\u001b[31m**Chunk 126**\u001b[0m\n",
      " a\n",
      "\n",
      "\t\t\u001b[31m**Chunk 127**\u001b[0m\n",
      " token\n",
      "\n",
      "\t\t\u001b[31m**Chunk 128**\u001b[0m\n",
      " of\n",
      "\n",
      "\t\t\u001b[31m**Chunk 129**\u001b[0m\n",
      " our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 130**\u001b[0m\n",
      " commit\n",
      "\n",
      "\t\t\u001b[31m**Chunk 131**\u001b[0m\n",
      "ment\n",
      "\n",
      "\t\t\u001b[31m**Chunk 132**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 133**\u001b[0m\n",
      " your\n",
      "\n",
      "\t\t\u001b[31m**Chunk 134**\u001b[0m\n",
      " satisfaction\n",
      "\n",
      "\t\t\u001b[31m**Chunk 135**\u001b[0m\n",
      ",\n",
      "\n",
      "\t\t\u001b[31m**Chunk 136**\u001b[0m\n",
      " I\n",
      "\n",
      "\t\t\u001b[31m**Chunk 137**\u001b[0m\n",
      " would\n",
      "\n",
      "\t\t\u001b[31m**Chunk 138**\u001b[0m\n",
      " like\n",
      "\n",
      "\t\t\u001b[31m**Chunk 139**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 140**\u001b[0m\n",
      " offer\n",
      "\n",
      "\t\t\u001b[31m**Chunk 141**\u001b[0m\n",
      " you\n",
      "\n",
      "\t\t\u001b[31m**Chunk 142**\u001b[0m\n",
      " a\n",
      "\n",
      "\t\t\u001b[31m**Chunk 143**\u001b[0m\n",
      " compl\n",
      "\n",
      "\t\t\u001b[31m**Chunk 144**\u001b[0m\n",
      "iment\n",
      "\n",
      "\t\t\u001b[31m**Chunk 145**\u001b[0m\n",
      "ary\n",
      "\n",
      "\t\t\u001b[31m**Chunk 146**\u001b[0m\n",
      " one\n",
      "\n",
      "\t\t\u001b[31m**Chunk 147**\u001b[0m\n",
      "-\n",
      "\n",
      "\t\t\u001b[31m**Chunk 148**\u001b[0m\n",
      "month\n",
      "\n",
      "\t\t\u001b[31m**Chunk 149**\u001b[0m\n",
      " subscription\n",
      "\n",
      "\t\t\u001b[31m**Chunk 150**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 151**\u001b[0m\n",
      " our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 152**\u001b[0m\n",
      " prem\n",
      "\n",
      "\t\t\u001b[31m**Chunk 153**\u001b[0m\n",
      "ium\n",
      "\n",
      "\t\t\u001b[31m**Chunk 154**\u001b[0m\n",
      " support\n",
      "\n",
      "\t\t\u001b[31m**Chunk 155**\u001b[0m\n",
      " service\n",
      "\n",
      "\t\t\u001b[31m**Chunk 156**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 157**\u001b[0m\n",
      " This\n",
      "\n",
      "\t\t\u001b[31m**Chunk 158**\u001b[0m\n",
      " service\n",
      "\n",
      "\t\t\u001b[31m**Chunk 159**\u001b[0m\n",
      " includes\n",
      "\n",
      "\t\t\u001b[31m**Chunk 160**\u001b[0m\n",
      " priority\n",
      "\n",
      "\t\t\u001b[31m**Chunk 161**\u001b[0m\n",
      " support\n",
      "\n",
      "\t\t\u001b[31m**Chunk 162**\u001b[0m\n",
      ",\n",
      "\n",
      "\t\t\u001b[31m**Chunk 163**\u001b[0m\n",
      " dedicated\n",
      "\n",
      "\t\t\u001b[31m**Chunk 164**\u001b[0m\n",
      " account\n",
      "\n",
      "\t\t\u001b[31m**Chunk 165**\u001b[0m\n",
      " management\n",
      "\n",
      "\t\t\u001b[31m**Chunk 166**\u001b[0m\n",
      ",\n",
      "\n",
      "\t\t\u001b[31m**Chunk 167**\u001b[0m\n",
      " and\n",
      "\n",
      "\t\t\u001b[31m**Chunk 168**\u001b[0m\n",
      " access\n",
      "\n",
      "\t\t\u001b[31m**Chunk 169**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 170**\u001b[0m\n",
      " our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 171**\u001b[0m\n",
      " advanced\n",
      "\n",
      "\t\t\u001b[31m**Chunk 172**\u001b[0m\n",
      " technical\n",
      "\n",
      "\t\t\u001b[31m**Chunk 173**\u001b[0m\n",
      " support\n",
      "\n",
      "\t\t\u001b[31m**Chunk 174**\u001b[0m\n",
      " team\n",
      "\n",
      "\t\t\u001b[31m**Chunk 175**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 176**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 177**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 178**\u001b[0m\n",
      "Please\n",
      "\n",
      "\t\t\u001b[31m**Chunk 179**\u001b[0m\n",
      " let\n",
      "\n",
      "\t\t\u001b[31m**Chunk 180**\u001b[0m\n",
      " me\n",
      "\n",
      "\t\t\u001b[31m**Chunk 181**\u001b[0m\n",
      " know\n",
      "\n",
      "\t\t\u001b[31m**Chunk 182**\u001b[0m\n",
      " if\n",
      "\n",
      "\t\t\u001b[31m**Chunk 183**\u001b[0m\n",
      " there\n",
      "\n",
      "\t\t\u001b[31m**Chunk 184**\u001b[0m\n",
      " is\n",
      "\n",
      "\t\t\u001b[31m**Chunk 185**\u001b[0m\n",
      " anything\n",
      "\n",
      "\t\t\u001b[31m**Chunk 186**\u001b[0m\n",
      " else\n",
      "\n",
      "\t\t\u001b[31m**Chunk 187**\u001b[0m\n",
      " we\n",
      "\n",
      "\t\t\u001b[31m**Chunk 188**\u001b[0m\n",
      " can\n",
      "\n",
      "\t\t\u001b[31m**Chunk 189**\u001b[0m\n",
      " do\n",
      "\n",
      "\t\t\u001b[31m**Chunk 190**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 191**\u001b[0m\n",
      " resolve\n",
      "\n",
      "\t\t\u001b[31m**Chunk 192**\u001b[0m\n",
      " your\n",
      "\n",
      "\t\t\u001b[31m**Chunk 193**\u001b[0m\n",
      " issue\n",
      "\n",
      "\t\t\u001b[31m**Chunk 194**\u001b[0m\n",
      " and\n",
      "\n",
      "\t\t\u001b[31m**Chunk 195**\u001b[0m\n",
      " improve\n",
      "\n",
      "\t\t\u001b[31m**Chunk 196**\u001b[0m\n",
      " your\n",
      "\n",
      "\t\t\u001b[31m**Chunk 197**\u001b[0m\n",
      " experience\n",
      "\n",
      "\t\t\u001b[31m**Chunk 198**\u001b[0m\n",
      " with\n",
      "\n",
      "\t\t\u001b[31m**Chunk 199**\u001b[0m\n",
      " our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 200**\u001b[0m\n",
      " company\n",
      "\n",
      "\t\t\u001b[31m**Chunk 201**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 202**\u001b[0m\n",
      " Your\n",
      "\n",
      "\t\t\u001b[31m**Chunk 203**\u001b[0m\n",
      " satisfaction\n",
      "\n",
      "\t\t\u001b[31m**Chunk 204**\u001b[0m\n",
      " is\n",
      "\n",
      "\t\t\u001b[31m**Chunk 205**\u001b[0m\n",
      " our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 206**\u001b[0m\n",
      " top\n",
      "\n",
      "\t\t\u001b[31m**Chunk 207**\u001b[0m\n",
      " priority\n",
      "\n",
      "\t\t\u001b[31m**Chunk 208**\u001b[0m\n",
      " and\n",
      "\n",
      "\t\t\u001b[31m**Chunk 209**\u001b[0m\n",
      " we\n",
      "\n",
      "\t\t\u001b[31m**Chunk 210**\u001b[0m\n",
      " value\n",
      "\n",
      "\t\t\u001b[31m**Chunk 211**\u001b[0m\n",
      " your\n",
      "\n",
      "\t\t\u001b[31m**Chunk 212**\u001b[0m\n",
      " business\n",
      "\n",
      "\t\t\u001b[31m**Chunk 213**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 214**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 215**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 216**\u001b[0m\n",
      "Thank\n",
      "\n",
      "\t\t\u001b[31m**Chunk 217**\u001b[0m\n",
      " you\n",
      "\n",
      "\t\t\u001b[31m**Chunk 218**\u001b[0m\n",
      " for\n",
      "\n",
      "\t\t\u001b[31m**Chunk 219**\u001b[0m\n",
      " bringing\n",
      "\n",
      "\t\t\u001b[31m**Chunk 220**\u001b[0m\n",
      " this\n",
      "\n",
      "\t\t\u001b[31m**Chunk 221**\u001b[0m\n",
      " to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 222**\u001b[0m\n",
      " our\n",
      "\n",
      "\t\t\u001b[31m**Chunk 223**\u001b[0m\n",
      " attention\n",
      "\n",
      "\t\t\u001b[31m**Chunk 224**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 225**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 226**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 227**\u001b[0m\n",
      "S\n",
      "\n",
      "\t\t\u001b[31m**Chunk 228**\u001b[0m\n",
      "in\n",
      "\n",
      "\t\t\u001b[31m**Chunk 229**\u001b[0m\n",
      "cer\n",
      "\n",
      "\t\t\u001b[31m**Chunk 230**\u001b[0m\n",
      "ely\n",
      "\n",
      "\t\t\u001b[31m**Chunk 231**\u001b[0m\n",
      ",\n",
      "\n",
      "\t\t\u001b[31m**Chunk 232**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 233**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 234**\u001b[0m\n",
      "Bob\n",
      "\n",
      "\t\t\u001b[31m**Chunk 235**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 236**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 237**\u001b[0m\n",
      "Customer\n",
      "\n",
      "\t\t\u001b[31m**Chunk 238**\u001b[0m\n",
      " Service\n",
      "\n",
      "\t\t\u001b[31m**Chunk 239**\u001b[0m\n",
      " Manager\n",
      "\n",
      "\t\t\u001b[31m**Chunk 240**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 241**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 242**\u001b[0m\n",
      "Company\n",
      "\n",
      "\t\t\u001b[31m**Chunk 243**\u001b[0m\n",
      " Name\n",
      "\n",
      "\t\t\u001b[31m**Chunk 244**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 245**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 246**\u001b[0m\n",
      "Email\n",
      "\n",
      "\t\t\u001b[31m**Chunk 247**\u001b[0m\n",
      ":\n",
      "\n",
      "\t\t\u001b[31m**Chunk 248**\u001b[0m\n",
      " [\n",
      "\n",
      "\t\t\u001b[31m**Chunk 249**\u001b[0m\n",
      "b\n",
      "\n",
      "\t\t\u001b[31m**Chunk 250**\u001b[0m\n",
      "ob\n",
      "\n",
      "\t\t\u001b[31m**Chunk 251**\u001b[0m\n",
      "@\n",
      "\n",
      "\t\t\u001b[31m**Chunk 252**\u001b[0m\n",
      "comp\n",
      "\n",
      "\t\t\u001b[31m**Chunk 253**\u001b[0m\n",
      "an\n",
      "\n",
      "\t\t\u001b[31m**Chunk 254**\u001b[0m\n",
      "yn\n",
      "\n",
      "\t\t\u001b[31m**Chunk 255**\u001b[0m\n",
      "ame\n",
      "\n",
      "\t\t\u001b[31m**Chunk 256**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 257**\u001b[0m\n",
      "com\n",
      "\n",
      "\t\t\u001b[31m**Chunk 258**\u001b[0m\n",
      "](\n",
      "\n",
      "\t\t\u001b[31m**Chunk 259**\u001b[0m\n",
      "mail\n",
      "\n",
      "\t\t\u001b[31m**Chunk 260**\u001b[0m\n",
      "to\n",
      "\n",
      "\t\t\u001b[31m**Chunk 261**\u001b[0m\n",
      ":\n",
      "\n",
      "\t\t\u001b[31m**Chunk 262**\u001b[0m\n",
      "b\n",
      "\n",
      "\t\t\u001b[31m**Chunk 263**\u001b[0m\n",
      "ob\n",
      "\n",
      "\t\t\u001b[31m**Chunk 264**\u001b[0m\n",
      "@\n",
      "\n",
      "\t\t\u001b[31m**Chunk 265**\u001b[0m\n",
      "comp\n",
      "\n",
      "\t\t\u001b[31m**Chunk 266**\u001b[0m\n",
      "an\n",
      "\n",
      "\t\t\u001b[31m**Chunk 267**\u001b[0m\n",
      "yn\n",
      "\n",
      "\t\t\u001b[31m**Chunk 268**\u001b[0m\n",
      "ame\n",
      "\n",
      "\t\t\u001b[31m**Chunk 269**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 270**\u001b[0m\n",
      "com\n",
      "\n",
      "\t\t\u001b[31m**Chunk 271**\u001b[0m\n",
      ")\n",
      "\n",
      "\t\t\u001b[31m**Chunk 272**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 273**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 274**\u001b[0m\n",
      "Phone\n",
      "\n",
      "\t\t\u001b[31m**Chunk 275**\u001b[0m\n",
      ":\n",
      "\n",
      "\t\t\u001b[31m**Chunk 276**\u001b[0m\n",
      " \n",
      "\n",
      "\t\t\u001b[31m**Chunk 277**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 278**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 279**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 280**\u001b[0m\n",
      "-\n",
      "\n",
      "\t\t\u001b[31m**Chunk 281**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 282**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 283**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 284**\u001b[0m\n",
      "-\n",
      "\n",
      "\t\t\u001b[31m**Chunk 285**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 286**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 287**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 288**\u001b[0m\n",
      "5\n",
      "\n",
      "\t\t\u001b[31m**Chunk 289**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 290**\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\t\t\u001b[31m**Chunk 291**\u001b[0m\n",
      "Please\n",
      "\n",
      "\t\t\u001b[31m**Chunk 292**\u001b[0m\n",
      " let\n",
      "\n",
      "\t\t\u001b[31m**Chunk 293**\u001b[0m\n",
      " me\n",
      "\n",
      "\t\t\u001b[31m**Chunk 294**\u001b[0m\n",
      " know\n",
      "\n",
      "\t\t\u001b[31m**Chunk 295**\u001b[0m\n",
      " if\n",
      "\n",
      "\t\t\u001b[31m**Chunk 296**\u001b[0m\n",
      " you\n",
      "\n",
      "\t\t\u001b[31m**Chunk 297**\u001b[0m\n",
      " have\n",
      "\n",
      "\t\t\u001b[31m**Chunk 298**\u001b[0m\n",
      " any\n",
      "\n",
      "\t\t\u001b[31m**Chunk 299**\u001b[0m\n",
      " other\n",
      "\n",
      "\t\t\u001b[31m**Chunk 300**\u001b[0m\n",
      " questions\n",
      "\n",
      "\t\t\u001b[31m**Chunk 301**\u001b[0m\n",
      " or\n",
      "\n",
      "\t\t\u001b[31m**Chunk 302**\u001b[0m\n",
      " if\n",
      "\n",
      "\t\t\u001b[31m**Chunk 303**\u001b[0m\n",
      " there\n",
      "\n",
      "\t\t\u001b[31m**Chunk 304**\u001b[0m\n",
      " is\n",
      "\n",
      "\t\t\u001b[31m**Chunk 305**\u001b[0m\n",
      " anything\n",
      "\n",
      "\t\t\u001b[31m**Chunk 306**\u001b[0m\n",
      " else\n",
      "\n",
      "\t\t\u001b[31m**Chunk 307**\u001b[0m\n",
      " I\n",
      "\n",
      "\t\t\u001b[31m**Chunk 308**\u001b[0m\n",
      " can\n",
      "\n",
      "\t\t\u001b[31m**Chunk 309**\u001b[0m\n",
      " assist\n",
      "\n",
      "\t\t\u001b[31m**Chunk 310**\u001b[0m\n",
      " you\n",
      "\n",
      "\t\t\u001b[31m**Chunk 311**\u001b[0m\n",
      " with\n",
      "\n",
      "\t\t\u001b[31m**Chunk 312**\u001b[0m\n",
      ".\n",
      "\n",
      "\t\t\u001b[31m**Chunk 313**\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "try:\n",
    "    \n",
    "    response = boto3_bedrock.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    stream = response.get('body')\n",
    "    \n",
    "    i = 1\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                text = chunk_obj['generation']\n",
    "                output.append(text)\n",
    "                print(f'\\t\\t\\x1b[31m**Chunk {i}**\\x1b[0m\\n{text}\\n')\n",
    "                i+=1\n",
    "            \n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a788be5",
   "metadata": {},
   "source": [
    "The above helps to quickly get output of the model and let the service complete it as you read. This assists in use-cases where there are longer pieces of text that you request the model to generate. You can later combine all the chunks generated to form the complete output and use it for your use-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02d48c73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\u001b[31m**COMPLETE OUTPUT**\u001b[0m\n",
      "\n",
      "\n",
      "Subject: Apology and Resolution for Poor Service Experience\n",
      "\n",
      "Dear John,\n",
      "\n",
      "I am writing to apologize for the poor service experience you recently had with our customer support engineer, James. We take all feedback seriously and are committed to providing the highest level of service to our customers.\n",
      "\n",
      "I have reviewed the details of your case and I want to assure you that we are taking immediate action to address the issues you encountered. Our team is working diligently to resolve the problems you faced and to prevent them from happening again in the future.\n",
      "\n",
      "As a token of our commitment to your satisfaction, I would like to offer you a complimentary one-month subscription to our premium support service. This service includes priority support, dedicated account management, and access to our advanced technical support team.\n",
      "\n",
      "Please let me know if there is anything else we can do to resolve your issue and improve your experience with our company. Your satisfaction is our top priority and we value your business.\n",
      "\n",
      "Thank you for bringing this to our attention.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "Bob\n",
      "\n",
      "Customer Service Manager\n",
      "\n",
      "Company Name\n",
      "\n",
      "Email: [bob@companyname.com](mailto:bob@companyname.com)\n",
      "\n",
      "Phone: 555-555-5555\n",
      "\n",
      "Please let me know if you have any other questions or if there is anything else I can assist you with.\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\x1b[31m**COMPLETE OUTPUT**\\x1b[0m\\n')\n",
    "outputText = ''.join(output)\n",
    "email = outputText[outputText.index('\\n')+1:]\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b08b3b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You have now experimented with using `boto3` SDK which provides a vanilla exposure to Amazon Bedrock API. Using this API you have seen the use case of generating an email responding to a customer due to their negative feedback.\n",
    "\n",
    "### Take aways\n",
    "- Adapt this notebook to experiment with different models available through Amazon Bedrock such as Anthropic Claude and AI21 Labs Jurassic models.\n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Play with the token length to understand the latency and responsiveness of the service.\n",
    "- Apply different prompt engineering principles to get better outputs.\n",
    "\n",
    "## Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf9261-1002-4da7-9124-943f72b43486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
