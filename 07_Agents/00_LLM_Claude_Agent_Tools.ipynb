{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedrock model integration with Langchain Agents\n",
    "\n",
    "Certain applications demand an adaptable sequence of calls to language models and various utilities depending on user input. The Agent interface enables such flexibility for these applications. An agent has availability to a range of resources and selects which ones to utilize based on the user input. Agents are capable of using multiple tools and utilizing the output of one tool as the input for the next.  \n",
    "\n",
    "There are two primary categories of agents:\n",
    "\n",
    "- Action agents: At each interval, determine the subsequent action utilizing the outputs of all previous actions. \n",
    "- Plan-and-execute agents: Determine the complete order of actions initially, then implement them all without updating the plan.\n",
    "\n",
    "In this notebook, we will demonstrate the use `plan-and-execute` agents along with `Zero-shot ReAct` which i an action agent and uses the [`ReAct`](https://arxiv.org/pdf/2205.00445.pdf) framework to select the appropriate tool based exclusively on the tool's description. It requires you provide the description of each tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "os.environ['SERPAPI_API_KEY'] = '<SERPAPI_API_KEY>'\n",
    "boto3_bedrock = bedrock.get_bedrock_client(os.environ.get('BEDROCK_ASSUME_ROLE', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_parameter = {\"temperature\": 0.0, \"top_p\": .5, \"max_tokens_to_sample\": 2000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ReAct: Synergizing Reasoning and Acting in Language Models Framework\n",
    "Large language models can generate both explanations for their reasoning and task-specific responses in an alternating fashion. \n",
    "\n",
    "Producing reasoning explanations enables the model to infer, monitor, and revise action plans, and even handle unexpected scenarios. The action step allows the model to interface with and obtain information from external sources such as knowledge bases or environments.\n",
    "\n",
    "The ReAct framework could enable large language models to interact with external tools to obtain additional information that results in more accurate and fact-based responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain import LLMMathChain\n",
    "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock, model_kwargs=model_parameter)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "react_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "question = \"Human: Only answer the question asked. <question> What is Amazon SageMaker? What is its launch year multiplied by 2? </question> Assistant: Launch year multiplied by 2:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tools\n",
    "\n",
    "You can introduce your own tools within the agent to perform specific actions. These could consist of looking up data in a database, or making API calls. In this example, we'll stub out some tools that would make API calls on behalf of the agent. For simplicity, the code returns a hardcoded value, but experiment to create your own integrations.\n",
    "\n",
    "The example below pulls in two built-in tools for google search (SerpAPI) and a calculator (LLMMathChain). It also adds 4 custom tools:\n",
    "**EC2Search**: Simulates a search for EC2 instances given a tag name.\n",
    "**EC2Patch**: Simulates patching an EC2 instance.\n",
    "**EC2Stop**: Simulates shutting down an EC2 instance.\n",
    "**ChangeRecord**: Simulates writing a change record to a CMDB.\n",
    "\n",
    "Notice how the description provides context to when to use the tool. That is a key component - it uses the LLM to determine which tool, if any, best solves the question being asked. You don't need a word-for-word match, it will do its best to model which of the tools is the best fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=False)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "tools.append(Tool.from_function(\n",
    "        name=\"EC2Search\",\n",
    "        func=lambda x: f\"['i-00000000000','i-00000000001','i-00000000002']\",  # Mock Function, replace with a boto3 call\n",
    "        description=\"Use this when you need to list EC2 instances in json. It takes a single parameter named tagname\"\n",
    "    ))\n",
    "tools.append(Tool.from_function(\n",
    "        name=\"EC2Patch\",\n",
    "        func=lambda x: f\"{len(x.split(','))} instances patched\",  # Mock Function, replace with a boto3 call\n",
    "        description=\"Use this when you need to patch EC2 instances\"\n",
    "    ))\n",
    "tools.append(Tool.from_function(\n",
    "        name=\"EC2Stop\",\n",
    "        func=lambda x: f\"{len(x.split(','))} instances stopped\",  # Mock Function, replace with a boto3 call\n",
    "        description=\"Use this when you need to stop EC2 instances\"\n",
    "    ))\n",
    "\n",
    "def record_change(x):\n",
    "    print(f\"*{x}*\")\n",
    "    j = json.loads(x[1:-1])\n",
    "    return f\"instance {j['instance']}. ACTION: {j['changeType']} recorded in CMDB\" # Mock Function, replace with an API call\n",
    "\n",
    "tools.append(Tool.from_function(\n",
    "        name=\"ChangeRecord\",\n",
    "        func=record_change,  # Mock Function, replace with an api call\n",
    "        description=\"Use this when you need to update a change record in CMDB. This takes in a json document as the parameter. The element named 'instance' contains the instance and the element named 'changeType' is the change type.\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock, model_kwargs=model_parameter)\n",
    "\n",
    "react_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "question = \"\"\"Human: Please list my EC2 instances with the a tag delete. \n",
    "Next, patch each of the instances and record the patch change record in the CMDB with a change type of 'PATCH'. \n",
    "Finally, for each of the instances stop the instance and tell me how many were stopped. Assistant:\"\"\"\n",
    "\n",
    "result = react_agent.run(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the tool code\n",
    "Could you use GenAI to author the code in the tools? Sure! With caution, there is some variation in the code and \n",
    "may not be safe for execution without a human review.\n",
    "\n",
    "The following example uses the code generated by Claude to generate the tool. It replaces the EC2Search tool above with the boto python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "prompt_data = \"\"\"\n",
    "Human: You are an AI python code generator. You write really great code.\n",
    "\n",
    "Write a python function named list_tagged_instances with one parameter named tagname. \n",
    "\n",
    "The function queries the boto3 library to return a list all of the EC2 instances that have a tag equal to the tagname parameter. \n",
    "\n",
    "return the code inside <code></code>.\n",
    "Computer:\"\"\"\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-instant-v1\"  \n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "tree = ET.ElementTree(ET.fromstring(response_body.get(\"completion\")))\n",
    "python_code = tree.getroot().text\n",
    "\n",
    "display(Markdown(f'```{python_code}```'))\n",
    "\n",
    "exec(python_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the code\n",
    "If the code above looks reasonable, we can use it to run our agent.\n",
    "\n",
    "**Note - for this to work, you need an EC2 instance in this account with a tag named 'delete' and any value in the tag. It is case senstitive, so prior to executing this, create an EC2 instance and set it to the stopped state.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tool in tools:\n",
    "    if tool.name == \"EC2Search\":\n",
    "        tool.func = list_tagged_instances\n",
    "        \n",
    "llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock, model_kwargs=model_parameter)\n",
    "\n",
    "react_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "question = \"\"\"Human: Please list my EC2 instances with the a tag delete. \n",
    "Next, patch each of the instances and record the patch change record in the CMDB with a change type of 'PATCH'. \n",
    "Finally, for each of the instances stop the instance and tell me how many were stopped. Assistant:\"\"\"\n",
    "\n",
    "result = react_agent.run(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another variation - Search for an instance that does not exist\n",
    "The prompt changes to search for EC2 instances with a tag that does not exist, so no instances should be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"\"\"Human: Please list my EC2 instances with the a tag doesnotexist. \n",
    "Next, patch each of the instances and record the patch change record in the CMDB with a change type of 'PATCH'. \n",
    "Finally, for each of the instances stop the instance and tell me how many were stopped. Assistant:\"\"\"\n",
    "\n",
    "result = react_agent.run(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Tools\n",
    "A common use of an agent is to look up a record in a database. It would not be practical to include the full database in the context, so you can provide tools that perform actions against the datebase that eliminates hallucinations while maintining the conversational interactions.\n",
    "\n",
    "### SQL Database Agent\n",
    "Langachain has a SQL Database agent for demonstrating how to ask questions of a DB to get answers. For details, read this document: https://python.langchain.com/docs/integrations/toolkits/sql_database\n",
    "\n",
    "The agent will load the schema of the DB into context and generate SQL statements based on natural language questions. The SQL statement is then executed against the database and the results returned.\n",
    "\n",
    "### Data Agents\n",
    "While the SQL Database agent is useful for data exploration and generating queries, there are also cases where you want to \n",
    "For specific entities, a tool can be created to pull data from the database to provide context next steps in the prompt.\n",
    "\n",
    "The following example will simulate a DB query for a customer in the customer table. Replace this code with a lookup ib DynamoDB or a relation database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_table=[\n",
    "  {\n",
    "    \"id\": 1, \n",
    "    \"first_name\": \"John\", \n",
    "    \"last_name\": \"Doe\",\n",
    "    \"age\": 35,\n",
    "    \"postal_code\": \"90210\"\n",
    "  },\n",
    "  {  \n",
    "    \"id\": 2,\n",
    "    \"first_name\": \"Jane\",\n",
    "    \"last_name\": \"Smith\", \n",
    "    \"age\": 27,\n",
    "    \"postal_code\": \"12345\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 3, \n",
    "    \"first_name\": \"Bob\",\n",
    "    \"last_name\": \"Jones\",\n",
    "    \"age\": 42,\n",
    "    \"postal_code\": \"55555\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 4,\n",
    "    \"first_name\": \"Sara\", \n",
    "    \"last_name\": \"Miller\",\n",
    "    \"age\": 29, \n",
    "    \"postal_code\": \"13579\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 5,\n",
    "    \"first_name\": \"Mark\",\n",
    "    \"last_name\": \"Davis\",\n",
    "    \"age\": 31,\n",
    "    \"postal_code\": \"02468\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 6,\n",
    "    \"first_name\": \"Laura\",\n",
    "    \"last_name\": \"Wilson\",\n",
    "    \"age\": 24,\n",
    "    \"postal_code\": \"98765\" \n",
    "  },\n",
    "  {\n",
    "    \"id\": 7,\n",
    "    \"first_name\": \"Steve\",\n",
    "    \"last_name\": \"Moore\",\n",
    "    \"age\": 36,\n",
    "    \"postal_code\": \"11223\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 8,\n",
    "    \"first_name\": \"Michelle\",\n",
    "    \"last_name\": \"Chen\",\n",
    "    \"age\": 22,\n",
    "    \"orders\": [\n",
    "        {\n",
    "            \"order_id\": 1,\n",
    "            \"description\": \"An order of 1 dozen pencils\"\n",
    "        },\n",
    "        {\n",
    "            \"order_id\": 2,\n",
    "            \"description\": \"An order of 2 markers\"\n",
    "        }\n",
    "    ],\n",
    "    \"postal_code\": \"33215\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 9,\n",
    "    \"first_name\": \"David\",\n",
    "    \"last_name\": \"Lee\",\n",
    "    \"age\": 29,\n",
    "    \"postal_code\": \"99567\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": 10,\n",
    "    \"first_name\": \"Jessica\",\n",
    "    \"last_name\": \"Brown\",\n",
    "    \"age\": 18, \n",
    "    \"postal_code\": \"43210\"\n",
    "  }\n",
    "]\n",
    "\n",
    "def customer_lookup(id):\n",
    "    print(f\"search by customer {id}\")\n",
    "    for customer in customer_table:\n",
    "        if customer[\"id\"] == int(id):\n",
    "            print(f\"found customer {id} {customer}\")\n",
    "            return customer\n",
    "        \n",
    "    return None\n",
    "\n",
    "tools.append(Tool.from_function(\n",
    "        name=\"CustomerLookup\",\n",
    "        func=customer_lookup,  # Mock Function, replace with an api call\n",
    "        description=\"Use this when you need to lookup a customer by id.\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "react_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "question = \"\"\"Human: write one sentence summary about the information you know about the customer with an id of 8.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "result = react_agent.run(question)\n",
    "\n",
    "print(f\"{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Experimental) - Using plan-and-execute agent\n",
    "Plan and execute agents work by first determining a plan of action by identifying the necessary subtasks and steps. Then, they carry out that plan by executing each of the subtasks in sequence until the objective is accomplished. \n",
    "The planning is always done by a large language model and execution is usually done by separate agent (executor agent) which is equipped with tools. \n",
    "The plan and execute agents are most suitable at handling complex, long-term objectives that demand ongoing focus and coordination. An effective strategy is often to integrate the responsiveness of an action agent with the deliberative planning capacity of a planning and execution agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plan_llm = Bedrock(model_id=\"anthropic.claude-v1\", client=boto3_bedrock, model_kwargs=model_parameter)\n",
    "execute_llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock, model_kwargs=model_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=execute_llm, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "planner = load_chat_planner(plan_llm)\n",
    "executor = load_agent_executor(execute_llm, tools, verbose=True)\n",
    "pae_agent = PlanAndExecute(planner=planner, executor=executor, verbose=True, max_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pae_agent.run(\"What is Amazon SageMaker? What is its launch year multiplied by 2? Launch year multiplied by 2 is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
