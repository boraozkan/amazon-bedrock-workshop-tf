{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaa0028",
   "metadata": {},
   "source": [
    "# Amazon Nova Canvas Workshop: Creating a Visual Ad for Octank Dog Food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58829f95",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to the Amazon Nova Canvas Workshop! In this hands-on session, we'll explore the powerful capabilities of Amazon Nova Canvas to create a compelling visual ad for Octank, a premium dog food company.\n",
    "\n",
    "\n",
    "### Use Case\n",
    "\n",
    "Octank is launching a new dog food line and wants to create a visual ad. They have specific requirements:\n",
    "\n",
    "1. Generate an initial product package design for their premium dog food.\n",
    "2. Create variations of the package design, including a cartoon-style version.\n",
    "3. Design a special promotional package using specific brand colors.\n",
    "4. Produce a professional-looking ad with the product in a kitchen setting.\n",
    "5. Isolate the product image for use in various marketing materials.\n",
    "\n",
    "### Workshop Objectives\n",
    "\n",
    "By the end of this workshop, you will:\n",
    "\n",
    "1. Understand the key features of Amazon Nova Canvas\n",
    "2. Learn how to use these features for a real-world marketing scenario\n",
    "3. Gain hands-on experience with the Amazon Bedrock API for image generation tasks\n",
    "\n",
    "### Features We'll Use\n",
    "\n",
    "During the workshop, we'll leverage the following features of Amazon Nova Canvas:\n",
    "\n",
    "1. Text-to-Image: To create an initial product package design based on text description\n",
    "2. Image Conditioning: To create an initial product package design inspired by the reference image \n",
    "3. Image Variation: To create a new version of the reference image by adding more details\n",
    "4. Inpainting: Add more details in a specific area of the reference image\n",
    "5. Color Conditioning: To generate a special promotional package design using Octank's brand color palette\n",
    "6. Outpainting: To create a professional-looking ad with product in kitchen background\n",
    "7. Background Removal: To isolate the product image for use in various marketing materials\n",
    "8. Responsible AI - Blocked Prompts that are not appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce815609",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b28fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# External dependencies\n",
    "import boto3\n",
    "import botocore\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Set up Bedrock client\n",
    "boto3_bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99667e1",
   "metadata": {},
   "source": [
    "The following ultilty function visualizes generated images alongside optional reference images. It's essential for displaying and comparing the results of image generation tasks, allowing you to easily see the input, output, and any relevant color information in a single, organized plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030a9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility function: Define plot function\n",
    "def plot_images(base_images, prompt=None, seed=None, ref_image_path=None, color_codes=None, original_title=None, processed_title=None):\n",
    "    if ref_image_path and color_codes:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        num_subplots = 3\n",
    "    elif ref_image_path or color_codes:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        num_subplots = 2\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        num_subplots = 1\n",
    "    \n",
    "    axes = np.array(axes).ravel() \n",
    "    \n",
    "    current_subplot = 0\n",
    "    \n",
    "    if color_codes:\n",
    "        num_colors = len(color_codes)\n",
    "        color_width = 0.8 / num_colors\n",
    "        for i, color_code in enumerate(color_codes):\n",
    "            x = i * color_width\n",
    "            rect = plt.Rectangle((x, 0), color_width, 1, facecolor=f'{color_code}', edgecolor='white')\n",
    "            axes[current_subplot].add_patch(rect)\n",
    "        axes[current_subplot].set_xlim(0, 0.8)\n",
    "        axes[current_subplot].set_ylim(0, 1)\n",
    "        axes[current_subplot].set_title('Color Codes')\n",
    "        axes[current_subplot].axis('off')\n",
    "        current_subplot += 1\n",
    "    \n",
    "    if ref_image_path:\n",
    "        reference_image = Image.open(ref_image_path)\n",
    "        max_size = (512, 512)\n",
    "        reference_image.thumbnail(max_size)\n",
    "        axes[current_subplot].imshow(np.array(reference_image))\n",
    "        axes[current_subplot].set_title(original_title or 'Reference Image')\n",
    "        axes[current_subplot].axis('off')\n",
    "        current_subplot += 1\n",
    "    \n",
    "    axes[current_subplot].imshow(np.array(base_images[0]))\n",
    "    if processed_title:\n",
    "        axes[current_subplot].set_title(processed_title)\n",
    "    elif ref_image_path and seed is not None:\n",
    "        axes[current_subplot].set_title(f'Image Generated Based on Reference\\nSeed: {seed}')\n",
    "    elif seed is not None:\n",
    "        axes[current_subplot].set_title(f'Image Generated\\nSeed: {seed}')\n",
    "    else:\n",
    "        axes[current_subplot].set_title('Processed Image')\n",
    "    axes[current_subplot].axis('off')\n",
    "    \n",
    "    if prompt:\n",
    "        print(f\"Prompt: {prompt}\\n\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf02373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_image(base64_image, output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        file.write(base64.b64decode(base64_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469aeef",
   "metadata": {},
   "source": [
    "## Use Cases Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded7b00",
   "metadata": {},
   "source": [
    "### Step 1: Text to Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87cfb9",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Octank company wants to launch a new marketing campaign with a new set of marketing digital assets. The marketing team wants to get inspiration by leveraging image generator model to create some sample images.\n",
    "As a first step they want to generate an image from simple text.\n",
    "\n",
    "#### What are negative prompts?\n",
    "Negative prompts in  Amazon Nova Canvas are a way to guide the model on what not to include in the generated image. They help refine the output by specifying elements, styles, or qualities that you want to avoid in the final image. This negative prompt below is used to improve the quality of the generated dog food package image by explicitly telling the model to avoid common issues like poor rendering, lack of detail, and unclear text.\n",
    "\n",
    "#### What is reference_image_path ?\n",
    "This is the original image (assumed to be the original picture of the owner's dog). For the purpose of this workshop, we will generate an image with Nova Canvas in the first step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae708c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt\n",
    "prompt = \"A white packet of premium dog food with an American Eskimo dog on it, professional product photography. Dog food is named Octank.\"\n",
    "negative_prompts = \"poorly rendered, poor background details, poor packet details, poor text details, bleary text\"\n",
    "seed = 42\n",
    "\n",
    "# Specify path to store the output\n",
    "output_save_path = \"images/after_text-to-image.png\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef7682",
   "metadata": {},
   "source": [
    "The Amazon Bedrock `InvokeModel` provides access to Amazon Nova Canvas by setting the right model ID, and returns a JSON response including a [Base64 encoded string](https://en.wikipedia.org/wiki/Base64) that represents the (PNG) image.\n",
    "\n",
    "When making an `InvokeModel` request, we need to fill the `body` field with a JSON object that varies depending on the task (`taskType`) you wish to perform viz. text to image, image variation, inpainting or outpainting. The Amazon Nova Canvas models supports the following parameters:\n",
    "* `cfgscale` - determines how much the final image reflects the prompt. Specifies how strongly the generated image should adhere to the prompt. Use a lower value to introduce more randomness in the generation. Min 1.1 and  Max 10. Default is 8.0.\n",
    "* `seed` - a number used to initialize the generation, using the same seed with the same prompt + settings combination will produce the same results\n",
    "* `numberOfImages` - the number of times the image is sampled and produced. Min - 1 and Max 5. Default 1.\n",
    "* `quality` - determines the output image quality (`standard` or `premium`)\n",
    "\n",
    "> ☝️ For more information on available input parameters for the model, refer to the [Amazon Nova User Guide](https://docs.aws.amazon.com/nova/latest/userguide/image-generation.html).\n",
    "\n",
    "The cell below invokes the Amazon Nova Canvas model through Amazon Bedrock to create an initial image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87a6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate text-to-image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,                    # Required\n",
    "            \"negativeText\": negative_prompts   # Optional\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,   # Range: 1 to 5 \n",
    "            \"quality\": \"standard\",  # Options: standard or premium\n",
    "            \"height\": 1024,        \n",
    "            \"width\": 1024,         \n",
    "            \"cfgScale\": 7.5,       # Range: 1.0 (exclusive) to 10.0\n",
    "            \"seed\": 250 #100            # Range: 0 to 214783647\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.nova-canvas-v1:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# save output\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "# Plot output\n",
    "plot_images(response_images, processed_title=\"Generated Product Package\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93260f99",
   "metadata": {},
   "source": [
    "##### Background\n",
    "\n",
    "Now, the marketing team wants to leverage a reference image of the company owner's American Eskimo to create a product package design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753850b",
   "metadata": {},
   "source": [
    "### Step 2: Image Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265cb2b",
   "metadata": {},
   "source": [
    "Amazon Nova Canvas offers two image conditioning modes:\n",
    "\n",
    "- Canny Edge: Extract prominent edges from the reference image to guide the generation process. You can “draw” the foundations of your desired image, and the model will then fill in the details, textures, and final aesthetic based on your guidance.\n",
    "\n",
    "- Segmentation: Define specific regions/objects within the reference image for the model to generate content aligned with those areas.\n",
    "\n",
    "![Visual of Canny Edge and Segementation algorithms ](https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2024/08/01/2024-image-generator-v2-1-color-conditioning.jpg)\n",
    "\n",
    "Main parameters can be specified include:\n",
    "\n",
    "- **conditionImage** (Required) – A JPEG or PNG image that guides the layout and composition of the generated image. The image must be formatted as a Base64 string. See Input Images for additional requirements.\n",
    "- **controlMode** (Optional) – Specifies the conditioning mode should be used. Default value is “CANNY_EDGE”.\n",
    "    \n",
    "\t**CANNY_EDGE** – Elements of the generated image will follow the prominent contours, or “edges”, of the condition image closely.\n",
    "    \n",
    "\t**SEGMENTATION** – The condition image will be automatically analyzed to identify prominent content shapes. This analysis results in a segmentation mask which guides the generation, resulting in a generated image that closely follows the layout of the condition image but allows the model more freedom within the bounds of each content area.\n",
    "\n",
    "- **controlStrength** (Optional) – Specifies how similar the layout and composition of the generated image should be to the conditioningImage. Range in 0 to 1.0 with lower values used to introduce more randomness. Default value is 0.7.\n",
    "\n",
    "- **text** (Required) – A text prompt to generate the image. Must be 1 - 1024 characters in length.\n",
    "\n",
    "- **negativeText** (Optional) – A text prompt to define what not to include in the image. Must be 1 - 1024 characters in length.\n",
    "\n",
    "\n",
    "Note: If `controlMode` or `controlStrength` are provided, `conditionImage` must also be provided.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098df931",
   "metadata": {},
   "source": [
    "#### Background\n",
    "The marketing team wants now to see how the package looks like with a cartoon version of the same dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c270d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt, reference image\n",
    "prompt = \"a oil-painting dog food packet with a white american eskimo on the packet cover, dog food company name is Octank\"\n",
    "reference_image_path = \"images/after_text-to-image.png\"\n",
    "seed = 42# Can be any random number between 0 to 214783647\n",
    "\n",
    "# Specify path to store the output\n",
    "output_save_path = \"images/after_image_cartooning.png\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d093db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the reference image\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,  # Required\n",
    "            \"conditionImage\": reference_image_base64, # Optional\n",
    "            \"controlMode\": \"CANNY_EDGE\", # Optional: CANNY_EDGE | SEGMENTATION\n",
    "            \"controlStrength\": 0.7,  # Range: 0.2 to 1.0,\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": seed,\n",
    "            }\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.nova-canvas-v1:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60659f",
   "metadata": {},
   "source": [
    "### Step 3: Image Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587c9a4",
   "metadata": {},
   "source": [
    "#### Background\n",
    "\n",
    "\n",
    "Generating images from text is powerful but, in some cases, you will want your model to understand the style from certain image and directly transfer it to your output image.\n",
    "Rather than starting from scratch, image variation features enables us to do style transfer easily.\n",
    "\n",
    "Now, Octank wants to have a dog food packet with the same style showing in the reference image, let's see how easy this step could be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ffd82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt, reference image\n",
    "prompt = \"A white packet of premium dog food with an American Eskimo dog on it, professional product photography. Dog food is named Octank\"\n",
    "negative_prompt = \"bad quality, low resolution, cartoon\"\n",
    "reference_image_path = \"images/sketch_dog.png\"\n",
    "seed = 600 # Can be any random number between 0 to 214783647\n",
    "\n",
    "# Specify path to store the output\n",
    "output_save_path = \"images/after_image_variation.png\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ee929",
   "metadata": {},
   "source": [
    "Image variation (a.k.a. Instant Customization) – Uses 1 to 5 images and an optional prompt as input. It generates a new image that preserves the content of the input image(s), but variates its style and background.\n",
    "\n",
    "The imageVariationParams fields are defined below.\n",
    "\n",
    "images (Required) – A list of 1–5 images to use as references. Each must be in JPEG or PNG format and encoded as as Base64 strings. See Input Images for additional requirements.\n",
    "\n",
    "similarityStrength (Optional) – Specifies how similar the generated image should be to the input images(s). Range in 0.2 to 1.0 with lower values used to introduce more randomness.\n",
    "\n",
    "text (Optional) – A text prompt describing what to generate within the masked region. Must be 1 - 1024 characters in length. Omitting his field will instruct the model to remove the elements inside the masked area, replacing them with a seamless extension of the image background.\n",
    "\n",
    "negativeText (Optional) – A text prompt to define what not to include in the image. Must be 1 - 1024 characters in length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbdae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the reference image\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "body = json.dumps({\n",
    "     \"taskType\": \"IMAGE_VARIATION\",\n",
    "     \"imageVariationParams\": {\n",
    "         \"text\": prompt,              # Optional\n",
    "         \"negativeText\": negative_prompt,   # Optional\n",
    "         \"images\": [reference_image_base64],               # One image is required\n",
    "        #  \"similarityStrength\": 1.0\n",
    "     },\n",
    "     \"imageGenerationConfig\": {\n",
    "         \"numberOfImages\": 1,\n",
    "         \"quality\": \"premium\",\n",
    "         \"height\": 1024,\n",
    "         \"width\": 1024,\n",
    "         #\"cfgScale\": 10,\n",
    "         \"seed\": seed\n",
    "     }\n",
    " })\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.nova-canvas-v1:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cb7e2",
   "metadata": {},
   "source": [
    "### Step 4. Inpainting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59793dbf",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Octank has decided to refresh their product line by featuring different dog breeds on their packaging. However, they want to maintain consistency in the overall design and only change the dog image. This is where inpainting comes in handy. For this task, Octank wants to replace the American Eskimo dog on their current packaging with a Husky, while keeping the rest of the design intact.\n",
    "\n",
    "Let's use inpainting to help Octank update their packaging with a new dog breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea1698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt and reference image\n",
    "prompt = \"A white packet of premium dog food with Husky dog on it, professional product photography. Dog food is named Octank\"\n",
    "negative_prompts = \"bad quality, low res\"\n",
    "reference_image_path = \"images/after_image_cartooning.png\" \n",
    "mask_prompt = \"American Eskimo dog\"\n",
    "seed = 2 # Can be any random number between 0 to 214783647"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9ffe3",
   "metadata": {},
   "source": [
    "`text` (Optional) – A text prompt to define what to change inside the mask. If you don't include this field, the model tries to replace the entire mask area with the background. Must be <= 512 characters. negativeText (Optional) – A text prompt to define what not to include in the image. Must be <= 512 characters. The size limits for the input image and input mask are <= 1,408 on the longer side of image. The output size is the same as the input size.\n",
    "\n",
    "The `inPaintingParams` fields are described below. The mask defines the part of the image that you want to modify.\n",
    "\n",
    "- `image` (Required) – The JPEG or PNG image to modify, formatted as a string that specifies a sequence of pixels, each defined in RGB values and encoded in base64. For examples of how to encode an image into base64 and decode a base64-encoded string and transform it into an image, see the code examples.\n",
    "- You must define one of the following fields (but not both) in order to define.\n",
    "    - `maskPrompt` – A text prompt that defines the mask.\n",
    "    - `maskImage` – A string that defines the mask by specifying a sequence of pixels that is the same size as the image. Each pixel is turned into an RGB value of (0 0 0) (a pixel inside the mask) or (255 255 255) (a pixel outside the mask). For examples of how to encode an image into base64 and decode a base64-encoded string and transform it into an image, see the code examples.\n",
    "- `text` (Optional) – A text prompt to define what to change inside the mask. If you don't include this field, the model tries to replace the entire mask area with the background.\n",
    "- `negativeText` (Optional) – A text prompt to define what not to include in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a339e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    \n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"INPAINTING\",\n",
    "        \"inPaintingParams\": {\n",
    "            \"text\": prompt,  # Optional - what to change inside the mask\n",
    "            \"negativeText\": negative_prompts,    # Optional\n",
    "            \"image\": reference_image_base64,  # Required\n",
    "            \"maskPrompt\": mask_prompt,  # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "            # \"maskImage\": \"base64-encoded string\",   \n",
    "\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": seed,\n",
    "            }\n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.nova-canvas-v1:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbf2b2",
   "metadata": {},
   "source": [
    "### Step 5: Color Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b1029d",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Now, let's create a special promotional package design using Octank's brand color palette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c58f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt, reference image, color code and path to store the generated images\n",
    "prompt = \"A white packet of premium dog food with an American Eskimo dog on it, professional product photography. Dog food is named Octank.\"\n",
    "hex_color_code = [\"#81FC81\", \"#C9D688\", \"#FFFFFF\"]\n",
    "seed = 42 # Can be any random number between 0 to 214783647\n",
    "\n",
    "output_save_path = \"images/after_color_conditioning.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67de6b1",
   "metadata": {},
   "source": [
    "\n",
    "Amazon Nova Canvas's color conditioning feature allows users to generate images that follow a specified color palette. This can be done with or without a reference image. \n",
    "\n",
    "Here's a summary of the parameters for color conditioning:\n",
    "\n",
    "- colors (Required) – A list of up to 10 color codes defining the desired color palette for your image. Expressed as hexadecimal values in the form “#RRGGBB”. Examples: \"#00FF00\" (pure green), \"#FCF2AB\" (a warm yellow). The colors list has the strongest effect if a referenceImage image is not provided. Otherwise, the colors in the list and the colors from the reference image will both be used in the final output.\n",
    "- referenceImage (Optional) – A JPEG or PNG image to use as a subject and style reference. The colors of the image will also be incorporated into you final output, along with the colors in from the colors list. See Input Images for additional requirements.\n",
    "- text (Required) – A text prompt to generate the image. Must be 1 - 1024 characters in length.\n",
    "- negativeText (Optional) – A text prompt to define what not to include in the image. Must be 1 - 1024 characters in length.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f6ab4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the reference image\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "    \n",
    "# Generate image condition on color palette\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"COLOR_GUIDED_GENERATION\",\n",
    "    \"colorGuidedGenerationParams\": {\n",
    "        \"text\": prompt,\n",
    "        \"colors\": hex_color_code,\n",
    "    },\n",
    "    \"imageGenerationConfig\": {\n",
    "        \"numberOfImages\": 1,\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.nova-canvas-v1:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, color_codes = hex_color_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55313bba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 6: Outpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db52288",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Now, Octank wants to create a professional-looking ad with this new product with kitchen background. To do this kind of background replacement, we will use the outpainting feature offered by Nova Canvas models. \n",
    "\n",
    "We will first expand the image size to provide more room, then generating the new image using outpainting feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dd131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt and reference image\n",
    "prompt = \"Dog food packet on a kitchen countertop\"\n",
    "reference_image_path = \"images/after_color_conditioning.png\" \n",
    "#reference_image_path = \"images/after_image_cartooning.png\" \n",
    "mask_prompt = \"Dog food packet\"\n",
    "seed = 100 # Can be any random number between 0 to 214783647\n",
    "\n",
    "# Expansion setting\n",
    "target_width = 2048\n",
    "target_height = 2048\n",
    "horizontal_position_percent=0.3\n",
    "vertical_position_percent=0.5\n",
    "\n",
    "output_save_path = \"images/after_outpainting.png\" \n",
    "\n",
    "# Specify path to store the output\n",
    "expand_image_path = \"images/expanded_image.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde95a7",
   "metadata": {},
   "source": [
    "- image (Required) – The JPEG or PNG image to modify, formatted as a Base64 string. See Input Images for additional requirements.\n",
    "\n",
    "- You must define one of the following fields (but not both) in order to specify the area of the image to affect.\n",
    "\n",
    "maskPrompt – A natural language text prompt that describes the region(s) of the image to edit.\n",
    "\n",
    "maskImage – A black and white image in which pure black pixels indicate the area inside the mask and pure white pixels indicate the area outside the mask. The mask image must be the same dimensions at the input image.\n",
    "\n",
    "- outPaintingMode – There are two outpainting modes which determine how the mask you provide is interpreted.\n",
    "\n",
    "DEFAULT – This mode transitions smoothly between the masked area and non-masked area, using some of the pixels of the original background as the starting point for the new background. This mode is often best when you would like the new background to use similar colors as the original background near the edges of your mask, but can result in a halo effect if your prompt calls for a new background that will be very different from the original background.\n",
    "\n",
    "PRECISE – This mode adheres strictly to the mask’s bounds and is often the best option when you are making more significant changes to the background of your image.\n",
    "\n",
    "- text (Optional) – A text prompt describing what to generate within the masked region. Must be 1 - 1024 characters in length. Omitting his field will instruct the model to remove the elements inside the masked area, replacing them with a seamless extension of the image background.\n",
    "\n",
    "- negativeText (Optional) – A text prompt to define what not to include in the image. Must be 1 - 1024 characters in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e8041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load reference image\n",
    "original_image = Image.open(reference_image_path)\n",
    "original_width, original_height = original_image.size\n",
    "\n",
    "# Calculate the position of the original image on the expanded canvas.\n",
    "position = (\n",
    "    int((target_width - original_width) * horizontal_position_percent),\n",
    "    int((target_height - original_height) * vertical_position_percent),\n",
    ")\n",
    "\n",
    "# Create an input image which contains the original image with an expanded\n",
    "# canvas.\n",
    "input_image = Image.new(\"RGB\", (target_width, target_height), (235, 235, 235))\n",
    "input_image.paste(original_image, position)\n",
    "input_image.save(expand_image_path)\n",
    "    \n",
    "# Encode the reference image\n",
    "with open(expand_image_path, \"rb\") as image_file:\n",
    "    reference_image_base64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    \n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"OUTPAINTING\",\n",
    "        \"outPaintingParams\": {\n",
    "            \"text\": prompt,  # Required\n",
    "            \"image\": reference_image_base64,  # Required\n",
    "            \"maskPrompt\": mask_prompt,  # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "            \"outPaintingMode\": \"PRECISE\",  # One of \"PRECISE\" or \"DEFAULT\"\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": seed,\n",
    "            }\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.nova-canvas-v1:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "save_image(response_body.get(\"images\")[0], output_save_path)\n",
    "\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path = reference_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d389c5",
   "metadata": {},
   "source": [
    "### Step 7: Background Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7e20a",
   "metadata": {},
   "source": [
    "#### Background\n",
    "Octank has professional photos of their existing gourmet dog food. They want to use these images across various marketing materials with different background. In our last use case, we will use Background Removal feature from Amazon Nova Canvas to help Ocktank isolate its product image from their original backgrond.\n",
    "\n",
    "To use this feature, you just need to provide the image the model needs to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b109e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define image needs to be processed and path to store the generated images\n",
    "reference_image_path = \"images/after_outpainting.png\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae013c5b",
   "metadata": {},
   "source": [
    "The background removal task type automatically identifies multiple objects in the input image and removes the background. The output image has a transparent background.\n",
    "\n",
    "Request format\n",
    "`{\n",
    "    \"taskType\": \"BACKGROUND_REMOVAL\",\n",
    "    \"backgroundRemovalParams\": {\n",
    "        \"image\": \"base64-encoded string\"\n",
    "    }\n",
    "}`\n",
    "\n",
    "Response Format\n",
    "`{\n",
    "  \"images\": [\n",
    "    \"base64-encoded string\", \n",
    "    ...\n",
    "  ],\n",
    "  \"error\": \"string\" \n",
    "}`\n",
    "\n",
    "The backgroundRemovalParams field is described below.\n",
    "- `image` (Required) – The JPEG or PNG image to modify, formatted as a string that specifies a sequence of pixels, each defined in RGB values and encoded in base64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08084f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read image from file and encode it as base64 string.\n",
    "with open(reference_image_path, \"rb\") as image_file:\n",
    "    input_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"BACKGROUND_REMOVAL\",\n",
    "    \"backgroundRemovalParams\": {\n",
    "        \"image\": input_image,\n",
    "    }\n",
    "})\n",
    "\n",
    "response = boto3_bedrock.invoke_model(\n",
    "    body=body, \n",
    "    modelId=\"amazon.nova-canvas-v1:0\",\n",
    "    accept=\"application/json\", \n",
    "    contentType=\"application/json\"\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "response_images = [\n",
    "    Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "    for base64_image in response_body.get(\"images\")\n",
    "]\n",
    "\n",
    "# plot output\n",
    "plot_images(response_images, ref_image_path= reference_image_path, original_title='Original Image', processed_title='Processed Image without Background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d122b-f24b-4232-8451-cd36f95f17b6",
   "metadata": {},
   "source": [
    "## Responsible AI in action\n",
    "\n",
    "To continue supporting best practices in the responsible use of AI, Amazon Nova Canvas has built to detect and remove harmful content in the data, reject inappropriate content in the user input, and filter the models’ outputs that contain inappropriate content (such as hate speech, profanity, and violence). \n",
    "\n",
    "Octank marketing team wants generate an appealing campaign by placing and image of Scooby Doo on the package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400e126-c157-4def-89d2-44fd0d303ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt with some inputs blocked for being copyright image.\n",
    "prompt = \"A white packet of premium dog food with Scooby Doo on it, professional product photography. Dog food is named Octank.\"\n",
    "negative_prompts = \"poorly rendered, poor background details, poor packet details, poor text details, bleary text\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d54e6-8b18-4e83-92ca-80014eec3f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate text-to-image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,                    # Required\n",
    "            \"negativeText\": negative_prompts   # Optional\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,   # Range: 1 to 5 \n",
    "            \"quality\": \"standard\",  # Options: standard or premium\n",
    "            \"height\": 1024,       \n",
    "            \"width\": 1024,         \n",
    "            \"cfgScale\": 7.5,       # Range: 1.0 (exclusive) to 10.0\n",
    "            \"seed\": 42             # Range: 0 to 214783647\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = boto3_bedrock.invoke_model(\n",
    "        body=body, \n",
    "        modelId=\"amazon.nova-canvas-v1:0\",\n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    response_images = [\n",
    "        Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "        for base64_image in response_body.get(\"images\")\n",
    "    ]\n",
    "\n",
    "    # Plot output\n",
    "    plot_images(response_images, processed_title=\"Generated Product Package\")     \n",
    "\n",
    "# Handle ValidationException (Responsible AI)\n",
    "except boto3_bedrock.exceptions.ValidationException as error:\n",
    "    print(f\"An error occurred: {error}\")\n",
    "\n",
    "# Handle all the other errors\n",
    "except Exception as e:\n",
    "    # Handle any other unexpected exceptions\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe27821d-0dce-4bca-95a8-2fe0f939ac2a",
   "metadata": {},
   "source": [
    "#### Amazon Bedrock gives validation error as the input prompt is asking for images of Scooby Dog and hence violates copyright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec210f22",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78849103",
   "metadata": {},
   "source": [
    "In this workshop, we explored the powerful features of Amazon Nova Cnavas through the lens of Octank, a premium dog food company. We covered:\n",
    "\n",
    "- Text to Image\n",
    "- Image Conditioning\n",
    "- Color Variation\n",
    "- Inpainting\n",
    "- Color Conditioning\n",
    "- Outpainting\n",
    "- Background Removal\n",
    "- Responsible AI in action\n",
    "\n",
    "These tools enable Octank to efficiently create diverse, high-quality visuals for their marketing campaigns, maintaining brand consistency while adapting to various styles.\n",
    "\n",
    "You can now leverage this GenAI-powered image generation to enhance your own creative workflows!"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
